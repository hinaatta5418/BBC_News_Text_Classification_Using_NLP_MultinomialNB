{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "daf137ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "669259a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\hinaa\\\\Downloads\\\\bbc_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0ea4dba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e56e3be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleId    0\n",
       "Text         0\n",
       "Category     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a7303f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79936a39",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78e785",
   "metadata": {},
   "source": [
    "# Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f8027904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       worldcom ex-boss launches defence lawyers defe...\n",
       "1       german business confidence slides german busin...\n",
       "2       bbc poll indicates economic gloom citizens in ...\n",
       "3       lifestyle  governs mobile choice  faster  bett...\n",
       "4       enron bosses in $168m payout eighteen former e...\n",
       "                              ...                        \n",
       "1485    double eviction from big brother model caprice...\n",
       "1486    dj double act revamp chart show dj duo jk and ...\n",
       "1487    weak dollar hits reuters revenues at media gro...\n",
       "1488    apple ipod family expands market apple has exp...\n",
       "1489    santy worm makes unwelcome visit thousands of ...\n",
       "Name: Text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c15ac",
   "metadata": {},
   "source": [
    "# Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b09be8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def punct_removel(text):\n",
    "    trans=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "684de2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(punct_removel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c7615446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       worldcom exboss launches defence lawyers defen...\n",
       "1       german business confidence slides german busin...\n",
       "2       bbc poll indicates economic gloom citizens in ...\n",
       "3       lifestyle  governs mobile choice  faster  bett...\n",
       "4       enron bosses in 168m payout eighteen former en...\n",
       "                              ...                        \n",
       "1485    double eviction from big brother model caprice...\n",
       "1486    dj double act revamp chart show dj duo jk and ...\n",
       "1487    weak dollar hits reuters revenues at media gro...\n",
       "1488    apple ipod family expands market apple has exp...\n",
       "1489    santy worm makes unwelcome visit thousands of ...\n",
       "Name: Text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08528729",
   "metadata": {},
   "source": [
    "# Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0deea7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "038c901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6a6b3ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       worldcom exboss launches defence lawyers defen...\n",
       "1       german business confidence slides german busin...\n",
       "2       bbc poll indicates economic gloom citizens maj...\n",
       "3       lifestyle governs mobile choice faster better ...\n",
       "4       enron bosses 168m payout eighteen former enron...\n",
       "                              ...                        \n",
       "1485    double eviction big brother model caprice holb...\n",
       "1486    dj double act revamp chart show dj duo jk joel...\n",
       "1487    weak dollar hits reuters revenues media group ...\n",
       "1488    apple ipod family expands market apple expande...\n",
       "1489    santy worm makes unwelcome visit thousands web...\n",
       "Name: Text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d6b4a",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b41fb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d109d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_text'] = df['Text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "96a88b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [worldcom, exboss, launches, defence, lawyers,...\n",
       "1       [german, business, confidence, slides, german,...\n",
       "2       [bbc, poll, indicates, economic, gloom, citize...\n",
       "3       [lifestyle, governs, mobile, choice, faster, b...\n",
       "4       [enron, bosses, 168m, payout, eighteen, former...\n",
       "                              ...                        \n",
       "1485    [double, eviction, big, brother, model, capric...\n",
       "1486    [dj, double, act, revamp, chart, show, dj, duo...\n",
       "1487    [weak, dollar, hits, reuters, revenues, media,...\n",
       "1488    [apple, ipod, family, expands, market, apple, ...\n",
       "1489    [santy, worm, makes, unwelcome, visit, thousan...\n",
       "Name: tokenized_text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4993c6",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "68d2657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff0a6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(word) for word in tokens]\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "14957042",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stemmed_text = df['tokenized_text'].apply( stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75b51736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [worldcom, exboss, launch, defenc, lawyer, def...\n",
       "1       [german, busi, confid, slide, german, busi, co...\n",
       "2       [bbc, poll, indic, econom, gloom, citizen, maj...\n",
       "3       [lifestyl, govern, mobil, choic, faster, bette...\n",
       "4       [enron, boss, 168m, payout, eighteen, former, ...\n",
       "                              ...                        \n",
       "1485    [doubl, evict, big, brother, model, capric, ho...\n",
       "1486    [dj, doubl, act, revamp, chart, show, dj, duo,...\n",
       "1487    [weak, dollar, hit, reuter, revenu, media, gro...\n",
       "1488    [appl, ipod, famili, expand, market, appl, exp...\n",
       "1489    [santi, worm, make, unwelcom, visit, thousand,...\n",
       "Name: tokenized_text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556799f",
   "metadata": {},
   "source": [
    "# Lemmantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d6e77f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3e05aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_stemmed_text(stemmed_words):\n",
    "    if not isinstance(stemmed_words, list) or not all(isinstance(word, str) for word in stemmed_words):\n",
    "        raise ValueError(\"Input must be a list of strings.\")\n",
    "    \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c87b5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the lemmatization function to each row\n",
    "df['lemmatized_text'] = stemmed_text .apply(lemmatize_stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f20966c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       worldcom exboss launch defenc lawyer defend fo...\n",
       "1       german busi confid slide german busi confid fe...\n",
       "2       bbc poll indic econom gloom citizen major nati...\n",
       "3       lifestyl govern mobil choic faster better funk...\n",
       "4       enron bos 168m payout eighteen former enron di...\n",
       "                              ...                        \n",
       "1485    doubl evict big brother model capric holbi cit...\n",
       "1486    dj doubl act revamp chart show dj duo jk joel ...\n",
       "1487    weak dollar hit reuter revenu medium group reu...\n",
       "1488    appl ipod famili expand market appl expand ipo...\n",
       "1489    santi worm make unwelcom visit thousand websit...\n",
       "Name: lemmatized_text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8e6ea",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c1bcf33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ea2194f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      00  000  0001  00051  000acr  000ayear  000bn  000m  000seater  \\\n",
      "0      0    0     0      0       0         0      0     0          0   \n",
      "1      0    0     0      0       0         0      0     0          0   \n",
      "2      0    1     0      0       0         0      0     0          0   \n",
      "3      0    1     0      0       0         0      0     0          0   \n",
      "4      0    0     0      0       0         0      0     0          0   \n",
      "...   ..  ...   ...    ...     ...       ...    ...   ...        ...   \n",
      "1485   0    1     0      0       0         0      0     0          0   \n",
      "1486   0    0     0      0       0         0      0     0          0   \n",
      "1487   0    0     0      0       0         0      0     0          0   \n",
      "1488   0    0     0      0       0         0      0     0          0   \n",
      "1489   0    1     0      0       0         0      0     0          0   \n",
      "\n",
      "      000strong  ...  zombi  zone  zonealarm  zoom  zooropa  zorro  zuluaga  \\\n",
      "0             0  ...      0     0          0     0        0      0        0   \n",
      "1             0  ...      0     0          0     0        0      0        0   \n",
      "2             0  ...      0     0          0     0        0      0        0   \n",
      "3             0  ...      0     0          0     0        0      0        0   \n",
      "4             0  ...      0     0          0     0        0      0        0   \n",
      "...         ...  ...    ...   ...        ...   ...      ...    ...      ...   \n",
      "1485          0  ...      0     0          0     0        0      0        0   \n",
      "1486          0  ...      0     0          0     0        0      0        0   \n",
      "1487          0  ...      0     0          0     0        0      0        0   \n",
      "1488          0  ...      0     0          0     0        0      0        0   \n",
      "1489          0  ...      0     0          0     0        0      0        0   \n",
      "\n",
      "      zurich  zuton  zvonareva  \n",
      "0          0      0          0  \n",
      "1          0      0          0  \n",
      "2          0      0          0  \n",
      "3          0      0          0  \n",
      "4          0      0          0  \n",
      "...      ...    ...        ...  \n",
      "1485       0      0          0  \n",
      "1486       0      0          0  \n",
      "1487       0      0          0  \n",
      "1488       0      0          0  \n",
      "1489       0      0          0  \n",
      "\n",
      "[1490 rows x 19653 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the lemmatized text data\n",
    "X = vectorizer.fit_transform(df['lemmatized_text'])\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the DataFrame\n",
    "print(vectorized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eae75705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_models(text_data, ngram_range):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    X = vectorizer.fit_transform(text_data)\n",
    "    return X, vectorizer\n",
    "\n",
    "# Unigrams\n",
    "X_unigrams, vectorizer_unigrams = create_ngram_models(df['lemmatized_text'], (1, 1))\n",
    "\n",
    "# Bigrams\n",
    "X_bigrams, vectorizer_bigrams = create_ngram_models(df['lemmatized_text'], (2, 2))\n",
    "\n",
    "# Trigrams\n",
    "X_trigrams, vectorizer_trigrams = create_ngram_models(df['lemmatized_text'], (3, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1668196",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3cda4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9458ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9e7c6d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86d7a6",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "01e5c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d6b21302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ff84b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abbbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
